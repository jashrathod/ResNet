/ext3/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 14 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
===== MODEL SUMMARY =====
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 32, 32, 32]             896
       BatchNorm2d-2           [-1, 32, 32, 32]              64
            Conv2d-3           [-1, 32, 32, 32]           9,248
       BatchNorm2d-4           [-1, 32, 32, 32]              64
            Conv2d-5           [-1, 32, 32, 32]           9,248
       BatchNorm2d-6           [-1, 32, 32, 32]              64
        BasicBlock-7           [-1, 32, 32, 32]               0
            Conv2d-8           [-1, 32, 32, 32]           9,248
       BatchNorm2d-9           [-1, 32, 32, 32]              64
           Conv2d-10           [-1, 32, 32, 32]           9,248
      BatchNorm2d-11           [-1, 32, 32, 32]              64
       BasicBlock-12           [-1, 32, 32, 32]               0
           Conv2d-13           [-1, 32, 32, 32]           9,248
      BatchNorm2d-14           [-1, 32, 32, 32]              64
           Conv2d-15           [-1, 32, 32, 32]           9,248
      BatchNorm2d-16           [-1, 32, 32, 32]              64
       BasicBlock-17           [-1, 32, 32, 32]               0
           Conv2d-18           [-1, 32, 32, 32]           9,248
      BatchNorm2d-19           [-1, 32, 32, 32]              64
           Conv2d-20           [-1, 32, 32, 32]           9,248
      BatchNorm2d-21           [-1, 32, 32, 32]              64
       BasicBlock-22           [-1, 32, 32, 32]               0
           Conv2d-23           [-1, 64, 16, 16]          18,496
      BatchNorm2d-24           [-1, 64, 16, 16]             128
           Conv2d-25           [-1, 64, 16, 16]          36,928
      BatchNorm2d-26           [-1, 64, 16, 16]             128
           Conv2d-27           [-1, 64, 16, 16]           2,112
      BatchNorm2d-28           [-1, 64, 16, 16]             128
       BasicBlock-29           [-1, 64, 16, 16]               0
           Conv2d-30           [-1, 64, 16, 16]          36,928
      BatchNorm2d-31           [-1, 64, 16, 16]             128
           Conv2d-32           [-1, 64, 16, 16]          36,928
      BatchNorm2d-33           [-1, 64, 16, 16]             128
       BasicBlock-34           [-1, 64, 16, 16]               0
           Conv2d-35           [-1, 64, 16, 16]          36,928
      BatchNorm2d-36           [-1, 64, 16, 16]             128
           Conv2d-37           [-1, 64, 16, 16]          36,928
      BatchNorm2d-38           [-1, 64, 16, 16]             128
       BasicBlock-39           [-1, 64, 16, 16]               0
           Conv2d-40           [-1, 64, 16, 16]          36,928
      BatchNorm2d-41           [-1, 64, 16, 16]             128
           Conv2d-42           [-1, 64, 16, 16]          36,928
      BatchNorm2d-43           [-1, 64, 16, 16]             128
       BasicBlock-44           [-1, 64, 16, 16]               0
           Conv2d-45            [-1, 128, 8, 8]          73,856
      BatchNorm2d-46            [-1, 128, 8, 8]             256
           Conv2d-47            [-1, 128, 8, 8]         147,584
      BatchNorm2d-48            [-1, 128, 8, 8]             256
           Conv2d-49            [-1, 128, 8, 8]           8,320
      BatchNorm2d-50            [-1, 128, 8, 8]             256
       BasicBlock-51            [-1, 128, 8, 8]               0
           Conv2d-52            [-1, 128, 8, 8]         147,584
      BatchNorm2d-53            [-1, 128, 8, 8]             256
           Conv2d-54            [-1, 128, 8, 8]         147,584
      BatchNorm2d-55            [-1, 128, 8, 8]             256
       BasicBlock-56            [-1, 128, 8, 8]               0
           Conv2d-57            [-1, 128, 8, 8]         147,584
      BatchNorm2d-58            [-1, 128, 8, 8]             256
           Conv2d-59            [-1, 128, 8, 8]         147,584
      BatchNorm2d-60            [-1, 128, 8, 8]             256
       BasicBlock-61            [-1, 128, 8, 8]               0
           Conv2d-62            [-1, 128, 8, 8]         147,584
      BatchNorm2d-63            [-1, 128, 8, 8]             256
           Conv2d-64            [-1, 128, 8, 8]         147,584
      BatchNorm2d-65            [-1, 128, 8, 8]             256
       BasicBlock-66            [-1, 128, 8, 8]               0
           Conv2d-67            [-1, 256, 4, 4]         295,168
      BatchNorm2d-68            [-1, 256, 4, 4]             512
           Conv2d-69            [-1, 256, 4, 4]         590,080
      BatchNorm2d-70            [-1, 256, 4, 4]             512
           Conv2d-71            [-1, 256, 4, 4]          33,024
      BatchNorm2d-72            [-1, 256, 4, 4]             512
       BasicBlock-73            [-1, 256, 4, 4]               0
           Conv2d-74            [-1, 256, 4, 4]         590,080
      BatchNorm2d-75            [-1, 256, 4, 4]             512
           Conv2d-76            [-1, 256, 4, 4]         590,080
      BatchNorm2d-77            [-1, 256, 4, 4]             512
       BasicBlock-78            [-1, 256, 4, 4]               0
           Linear-79                   [-1, 10]           2,570
================================================================
Total params: 3,576,842
Trainable params: 3,576,842
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 10.00
Params size (MB): 13.64
Estimated Total Size (MB): 23.66
----------------------------------------------------------------
None
Initializing fetching CIFAR10 dataset using torchvision
Files already downloaded and verified
Files already downloaded and verified
Total Trainable Parameters : 3576842
Total Epochs : 200 | Optimizer : adam | Learning Rate : 0.1 | Batch Size : 512
Data Augmentation : ['trivial_aug', 'horizontal_flip', 'random_crop']
Epoch : 0, Training Loss : 5.31450888671875, Testing Loss : 49435.1064, Training Accuracy : 0.10294, Testing Accuracy : 0.1287
Epoch : 10, Training Loss : 6.074587998046875, Testing Loss : 6.871425817871094, Training Accuracy : 0.10056, Testing Accuracy : 0.1
Epoch : 20, Training Loss : 4.808766064453125, Testing Loss : 5.672100146484375, Training Accuracy : 0.10006, Testing Accuracy : 0.1
slurmstepd: error: *** JOB 32272910 ON gr048 CANCELLED AT 2023-04-13T17:14:09 ***
